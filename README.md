# ğŸ’ŠNutrients Predict and Recommend
---
## 1. ê°œë°œ í™˜ê²½ (IDE)
- Win10
- Pycharm 2023.2
- Python 3.7

---
##  2. Project Objectives (í”„ë¡œì íŠ¸ ëª©í‘œ)
- I tried to compensate for the disappointment in the [last nutritional classification program](https://github.com/JiHyun-Jo7/IntelCapsule)  
In addition, a new nutritional recommendation system through symptoms was added to the program
- crawl nutritional information on iHub (https://iherb.com/), a famous nutritional supplement site around the world,  
Through this, 1. predict the effect with the name of nutritional supplements and  
2. Create a program that recommends nutritional supplements when providing symptoms
- [ì´ì „ì— ì§„í–‰í•œ ì˜ì–‘ì œ ë¶„ë¥˜ í”„ë¡œì íŠ¸](https://github.com/JiHyun-Jo7/IntelCapsule)ì—ì„œ ì•„ì‰¬ì› ë˜ ì ì„ ë³´ì™„í•˜ê³ ì í–ˆìœ¼ë©°,  
  ì „ì— ì—†ë˜ ì¦ìƒì„ í†µí•œ ì¶”ì²œ ì‹œìŠ¤í…œì„ ìƒˆë¡œ ì¶”ê°€í–ˆë‹¤
- ì „ì„¸ê³„ ìœ ëª… ì˜ì–‘ì œ ì‚¬ì´íŠ¸ì¸ [ì•„ì´í—ˆë¸Œ](https://kr.iherb.com/) ì—ì„œ ì˜ì–‘ì œ ì •ë³´ë¥¼ í¬ë¡¤ë§ í•œ í›„,  
  1. ì˜ì–‘ì œ ì´ë¦„ìœ¼ë¡œ íš¨ê³¼ë¥¼ ì¶”ì¸¡í•˜ê³  2. ì¦ìƒì„ ì œê³µí•˜ë©´ ì˜ì–‘ì œë¥¼ ì¶”ì²œí•˜ëŠ” í”„ë¡œê·¸ë ˜ì„ ë§Œë“ ë‹¤ 
---
## 3. Code Review
### 01. [Crawling Data](https://github.com/JiHyun-Jo7/Nutrients_Predict_and_Recommend/blob/14c4883aed4a2f3beeb2dda1c5409048e4b9d581/01_crawling_data.py)
```
# Before
for i in range(6):
    section_url = 'https://kr.iherb.com/c/{}'.format(category[i])
    df_titles = pd.DataFrame()
    titles = []
    for j in range(1, pages[i] + 1):  # pages[i]+1
        if j == 1:
            url = section_url
        else:
            url = section_url + '?p={}'.format(j)
        driver.get(url)
        time.sleep(3)
        product = driver.find_elements(By.CLASS_NAME, 'product-cell-container')
```
- ë°ì´í„° í¬ë¡¤ë§ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” ìƒí’ˆì˜ ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤ í•˜ì§€ë§Œ í•´ë‹¹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì œí’ˆë“¤ì˜ URLì—ëŠ” ê·œì¹™ì„±ì´ ì—†ë‹¤
- ì´ì „ í”„ë¡œì íŠ¸ì—ì„  pathë¥¼ ì‚¬ìš©í•˜ì—¬ ì œí’ˆ ì‚¬ì´íŠ¸ì— ì ‘ê·¼í–ˆëŠ”ë° í˜ì´ì§€ì— ì ‘ì†í• ë•Œë§ˆë‹¤ ì¿ í‚¤ í—ˆìš©ì„ ë°˜ë“œì‹œ í•´ì•¼í•´ í”¼ë¡œê°ì´ ì»¸ë‹¤
- ì¤‘ê°„ì— ëœ¨ëŠ” ê´‘ê³ ì°½ ë•Œë¬¸ì— PATH ë§ˆì € ë¶ˆê·œì¹™ì ìœ¼ë¡œ ë³€í–ˆê³  ì´ë¡œì¸í•´ PATHë¥¼ ì°¾ì§€ ëª»í•˜ëŠ” ì˜¤ë¥˜ê°€ ìì£¼ ë°œìƒí•´ ë§ì€ ì‹œê°„ì´ ì†Œìš”ëë‹¤
```
# After
        response = requests.get(section_url, headers=headers)
        response.raise_for_status()
        soup = bs(response.text, 'html.parser')

        product_url = []
        for z in soup.find_all('div', {'class': 'absolute-link-wrapper'}):
            for y in z.find_all({'a'}):
                if y.get('href') is not None:
                    product_url.append(y.get('href'))
        del product_url[0]              # Delete unrelated url
```
- ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„  ìë™ìœ¼ë¡œ ì¿ í‚¤ í—ˆìš©, ê´‘ê³ ì°½ì„ ì¢…ë£Œí•˜ì˜€ê³  ì œí’ˆ í˜ì´ì§€ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì ‘ì†í–ˆë‹¤
- ê·¸ ê²°ê³¼ ì˜¤ë¥˜ ë°œìƒ ë¹ˆë„ë„ ëŒ€í­ ê°ì†Œí•˜ì˜€ìœ¼ë©° í¬ë¡¤ë§ ì†Œìš” ì‹œê°„ ë˜í•œ ëŒ€í­ ê°ì†Œí•˜ì˜€ë‹¤

### 02. [Data Concat](https://github.com/JiHyun-Jo7/Nutrients_Predict_and_Recommend/blob/e2ea50df5acf610e29da6c590f75c5b2601d9b4f/02_data_concat.py)

### 03. [Preprocessing](https://github.com/JiHyun-Jo7/Nutrients_Predict_and_Recommend/blob/e2ea50df5acf610e29da6c590f75c5b2601d9b4f/03_preprocessing.py)
```
Z = np.array(df.name)
for i in range(len(Z)):
    if Z[i] is not None:
        for j in range(i):
            if i != j and Z[j] is not None:
                ratio = SequenceMatcher(None, Z[i], Z[j]).ratio()
                if ratio >= 0.95:
                    print('similar data,{} :{}'.format(i, Z[i]))
                    print('remove data,{} :{}'.format(j, Z[j]))
                    df.effect[j] = None
                    df.category[j] = None
                    df.name[j] = None
```
- Previous projects eliminated deduplication based on the product's validity, but this time, we tried deduplication based on the product name
- It was very effective in removing products with different capacities and flavors,  
but there was a problem that products by gender and age were removed together
- In addition, when duplicate tests were conducted in all categories, the number of data in the latter category became very poor
- ì´ì „ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì œí’ˆì˜ íš¨ê³¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µì„ ì œê±°í–ˆì§€ë§Œ ì´ë²ˆì—ëŠ” ì œí’ˆ ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ ì¤‘ë³µì²˜ë¦¬ë¥¼ ì‹œë„í–ˆë‹¤
- ìš©ëŸ‰, ë§›ì´ ë‹¤ë¥¸ ì œí’ˆì„ ì œê±°í•˜ëŠ”ë° ë§¤ìš° íš¨ê³¼ì ì´ì—ˆì§€ë§Œ ì„±ë³„, ì—°ë ¹ë³„ ì œí’ˆì´ í•¨ê»˜ ì œê±°ë˜ëŠ” ê²ƒì´ ë¬¸ì œì˜€ë‹¤
- ë˜í•œ ì¤‘ë³µ ê²€ì‚¬ë¥¼ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¡œ ê²€ì‚¬í•˜ë‹ˆ í›„ë°˜ ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„° ìˆ˜ê°€ ë§¤ìš° ë¹ˆì•½í•´ì§€ëŠ” ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤

```
for i in range(len(df.effect)):
    tk_x = okt.pos(df.effect[i], stem=True)
    df_token = pd.DataFrame(tk_x, columns=['word', 'class'])
    # ì˜ì–´, ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ í˜•íƒœì˜ ë‹¨ì–´ë§Œ ë‚¨ê¹€
    df_token = df_token[
        ((df_token['class'] == 'Alpha') | (df_token['class'] == 'Noun') | (df_token['class'] == 'Verb') | (df_token['class'] == 'Adjective'))]
    # ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ í˜•íƒœì˜ ë‹¨ì–´ë§Œ ë‚¨ê¹€
    # df_token = df_token[
    #     ((df_token['class'] == 'Noun') | (df_token['class'] == 'Verb') | (df_token['class'] == 'Adjective'))]
    print(df_token)
    words = []                                                 # í’ˆì‚¬ íƒœê·¸ ì œê±°
    for word in df_token.word:
        if 1 < len(word):                                      # í•œê¸€ì ë‹¨ì–´ ì œê±°
            if word not in stopwords:                          # ë¶ˆìš©ì–´ ì œê±°
                print(word)
                words.append(word)
                cleaned_sentence = ' '.join(words)
    print(cleaned_sentence)
    try:
        if len(cleaned_sentence.split()) < 15:                     # ë‹¨ì–´ê°€ 15ê°œ ë¯¸ë§Œì¸ ë¬¸ì¥ ì œê±°
            cleaned_sentence = None
    except: cleaned_sentence = None
    cleaned_sentences.append(cleaned_sentence)
df['cleaned_sentences'] = cleaned_sentences
```
- Save only English, nouns, verbs, and adjectives among morphemes and remove fire words
- Remove short sentences that do not help you learn
- í˜•íƒœì†Œ ì¤‘ ì˜ì–´, ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì‚´ë¦¬ê³  ë¶ˆìš©ì–´ë¥¼ ì œê±°
- í•™ìŠµì— ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” ì§§ì€ ë¬¸ì¥ì€ ì œê±°

### 04. [Model Learning](https://github.com/JiHyun-Jo7/Nutrients_Predict_and_Recommend/blob/e2ea50df5acf610e29da6c590f75c5b2601d9b4f/04_model_learning.py)
- 24 Categories
- Model structure
  - ì°¨ì› ì¶•ì†Œ ë ˆì´ì–´(Embedding), ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´(Conv1D), LSTM ë ˆì´ì–´ë¡œ êµ¬ì„±
  - Add Dropout Layer to prevent overfitting during learning
  - í•™ìŠµ ì¤‘ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ Dropout ë ˆì´ì–´ ì¶”ê°€

### 05. [Model_predict](https://github.com/JiHyun-Jo7/Nutrients_Predict_and_Recommend/blob/e2ea50df5acf610e29da6c590f75c5b2601d9b4f/05_model_predict.py)
- 6 categories (for testing) were predicted successfully, but 24 categories are in preprocessing ...
- ì¹´í…Œê³ ë¦¬ 6ê°œ(í…ŒìŠ¤íŠ¸ ìš©)ëŠ” ì˜ˆì¸¡ ì„±ê³µí•˜ì˜€ìœ¼ë‚˜ ì¹´í…Œê³ ë¦¬ 24ê°œëŠ” ì „ì²˜ë¦¬ ì§„í–‰ ì¤‘ ...
---
